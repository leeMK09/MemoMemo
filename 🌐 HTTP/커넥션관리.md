## TCP 커넥션

</br>

**HTTP GET 메서드 요청 흐름**

1. 목적지의 IP 와 Port 로 TCP 커넥션을 맺는다
2. 목적지 서버로 `GET` 요청을 한다
3. 응답메시지를 받는다
4. 커넥션을 끊는다

**TCP 데이터 흐름의 간략한 내용**

- 데이터 스트림이 들어오면 TCP 는 세그먼트 단위로 잘게 나누고 IP 패킷이라고 불리는 봉투에 담아서 보낸다
- IP 패킷 헤더 (20 byte) + TCP 세그먼트 헤더 (20 byte) + TCP 데이터 조각 (0 ~ 그 이상의 byte)
- 목적지 IP / 목적지 Port / 출발지 IP / 출발지 Port 에 따라 TCP 커넥션이 나뉜다
  - 모두 동일한 값의 TCP 커넥션은 없다

**TCP 소켓 인터페이스의 상호작용**

1. Server : `s = socket(param)` (소켓 생성)
2. Server : `bind(s, local IP, Port)` (소켓의 로컬 포트번호, IP 할당)
3. Server : `connect(s, remote IP, Port)` (로컬 ↔ 원격의 호스트 통신 연결, TCP 커넥션 생성)
4. Server : `listen(s ...)` (커넥션 열기)
5. Server : `s2 = accept(s)` (누군가 커넥션 맺기를 기다림)

---

6. Client : `socket` + `bind` + `connect` (소켓 생성 및 IP, Port 연결 그리고 Server 의 IP:Port 로 연결)
7. Server : `read` (Client 의 요청을 읽음)
8. Client : 성공적 연결 + HTTP 요청을 보냄 (`write`) + HTTP 응답을 기다림 (`read`)
9. Server : 요청 메시지 처리 + 응답을 보냄 (`write`)
10. Client : 응답을 처리
11. Client + Server : `close` (커넥션 닫기)

</br>
</br>

---

</br>

## HTTP 트랜잭션 지연 (TCP 지연)

</br>

### TCP 핸드세이크 지연

- Client TCP 패킷 (보통 40 ~ 60 byte)의 `SYN` 보냄 → `SYN` + `ACK` 를 다시 Client 에 보냄 → Client `ACK` 보냄
- 결국 크기가 작은 데이터를 보낼 때 문제가 발생하게 된다 → TCP 구성에 50% 이상의 시간을 소비한다

</br>

### 확인 응답 지연

- 인터넷 라우터가 과부하에 걸리면 패킷을 마음대로 파기한다 → 이것 때문에 TCP 가 성공적인 데이터 전송을 보장하기 위해 자체적인 확인 체계를 가지게 된다
- TCP 세그먼트 순번과 데이터 무결성 체크섬, 특정 시간안에 확인응답 메시지를 받지 못하면 오류가 있는 것으로 판단하여 다시 데이터를 전송한다
- 확인 응답은 크기가 작기 때문에 TCP는 같은 방향으로 송출되는 데이터 패킷에 확인응답을 편승 시킨다 (같이 끼워 팔아버림) → 송출 패킷 + 확인 응답이 묶어서 보내지므로 네트워크를 효율적으로 사용하게 된다
- 같이 끼워서 전송하는 경우를 좀더 늘리기 위해 확인 응답을 지연한다
  - 송출할 확인응답을 특정 시간동안 (0.1 ~ 0.2초) 버퍼에 저장해놓고 편승할 송출 데이터 패킷을 찾는다
  - 시간안에 못찾으면 별도 패킷으로 전송한다
  - 막상 편승할 패킷을 찾으려고 하면 해당 방향으로 송출될 패킷이 많지 않아 의미없어진다
  - 요청과 응답 두 가지 형식만으로 HTTP 는 동작한다

</br>

### TCP 느린 시작 (slow start)

- TCP는 처음 커넥션 맺으면 최대 속도를 제한한다
  - 초기 연결시, 송신자는 수신자의 수용 가능 속도나 네트워크의 대역폭을 모르게 때문에, 너무 많은 데이터를 보내면 패킷이 손실되고 혼잡이 발생할 수 있기 때문이다
- 그 이후 성공하게 되면 제한을 높인다 ← 급작스러운 부하와 혼잡을 방지
- 한번에 전송할 패킷 수를 제한한다
- 즉, 패킷이 성공적으로 전달되는 각 시점에 송신자는 추가로 2개의 패킷을 더 전송할 수 있는 권한을 얻게 된다.
- 확인응답을 받으면 2개의 패킷을 보냄, 이후에 4개의 패킷을 보낼 수 있게된다 (지수적으로 증가)
- 단점은 처음에 너무 빠르게 지수적으로 증가하다 보면 네트워크가 한계에 도달하게 되고 갑자기 많은 패킷이 손실될 수 있다 → Burst Loss
  - 이를 보안하기 위한 방법들이 존재한다 (TCP Vegas, TCP BBR)
- 혼잡제어 기능 때문에 새로운 커넥션은 이미 어느정도 데이터를 주고받은 "튜닝"된 커넥션 보다 느리다

</br>

### 네이글 알고리즘

- 작은 크기의 데이터는 그냥 보내기에 네트워크 성능에 크게 떨어지는 원인이 된다
- 패킷을 전송하기 전에 많은 양의 TCP 데이터를 한 개의 덩어리로 합쳐서 보낸다
- MTU (1,500 byte) 가 되지 않으면 전송하지 않는다 → 그러나 확인응답을 모두 받은 패킷이라면 버퍼에 저장된 데이터가 전송된다
- 확인응답 지연 + 네이글 알고리즘 ← 시간 많이 잡아먹는 주범

</br>

### TIME_WAIT 지연과 포트 고갈

- 보통 실제 상황에서 문제가 발생하지 않는데 성능 측정을 할 때 문제가 발생하게 된다
- TCP 커넥션을 끊으면 종단에서 커넥션의 IP 주소와 포트번호를 메모리의 작은 제어 영역(control block)에 기록하게 된다
- 보통 세그먼트의 최대 생명주기(1분) 의 두배(2분) 시간 동안 유지하게 된다 → 같은 구성의 새로운 커넥션 삽입문제를 방지한다
- 대략 계산했을 때 포트 수 (65535) 와 2분(120초) → 초당 500개 이상의 HTTP 트랜잭션을 처리하게 되면 이 문제가 발생하게 된다

</br>
</br>

---

</br>

## HTTP 커넥션 관리

- HTTP 헤더에는 `Connection` 이라는 TCP 커넥션에 관련된 헤더가 있다
- 이 헤더는 홉별 (`hop-by-hop`) 헤더 라서 인접한 두 서버간에서만 영향을 미치는 헤더 라는 의미이다

</br>

### HTTP 커넥션 잘 해보기

**병렬 커넥션**

- 여러개의 TCP 커넥션을 통한 동시 HTTP 요청
- 빠르다
- 그러나 컴퓨터 대역폭이 낮으면 더 오래 걸린다
- 빠르게 느껴질 수 있다 → 눈에 보일 정도로 빠르니까

<br>

**지속 커넥션**

- TCP 커넥션을 끊지 않고 계속 연결한다
- 튜닝된 커넥션을 사용하여 빠르다 → 패킷 수 2개, 4개, 8개 ...
- 하지만 계속 연결된 상태로 있는 수많은 커넥션이 쌓이게 되면 불필요한 소모가 생긴다
- HTTP/1.0+ : `keep-alive` , HTTP 1.1 에 지속 커넥션 (둘다 동일하다)
- 즉, Client 에서 `Connection: Keep-Alive` 헤더를 송신하면 Server 에서 만약 지원이 가능한 헤더라고 할 경우 똑같은 헤더를 보내고 아니라면 보내면 안된다

> 멍청한 프록시
>
> `Connection` 은 인접한 두 서버간에만 영향을 미치므로 프록시가 중간에 끼면 지속 커넥션을 무조건 없애야한다
> 그렇지않다면 프록시는 `Connection` 헤더의 의미를 모르고 그냥 모든 헤더를 통째로 다음 Server에 전달해버린다
> 그렇게될 경우 Client 와 Server 는 커넥션을 계속 맺는데 프록시는 커넥션을 끊는다 → Server 는 Connection 이 계속 연결된 것으로 착각하며 처리하게 된다
> 특히 보안 토큰이나 인증 정보를 hop-by-hop 헤더로 설정하고 있는데 프록시가 제대로 제거하지 않으면 유출 위험도 생길 수 있다
> `Proxy-Connection` 헤더라는 것이 존재하며 이 값으로 송신할 경우 프록시가 알아서 `Connection` 으로 변경해준다

</br>

**파이프라인 커넥션**

- HTTP 통신 입/출력을 큐에 쌓아서 처리하게 된다
