## 리더와 팔로워 (Leader-Follower 복제)

- **Replica** (레플리카)
    - 각 복사본을 가지고 있는 노드를 의미한다
- **Replica Set** (레플리카 셋)
    - 복사본들의 집합을 의미한다
- 리더와 팔로워를 설정하는 것이 가장 일반적인 복제 유지 방법
- 리더는 데이터 읽기와 쓰기가 가능하고, 팔로워는 읽기만 가능한 방식으로 동작
- 이러한 방법을 `Leader-Based` (또는 `Leader-Follower`, `Active-Passive`, `Master-Slave`) 복제라고 한다
- 복제를 수행하는 방법은 구현에 따라 다를 수 있으며, 일반적으로는 복제 로그 또는 `Stream` 을 사용해서 복제 수행을 한다

</br>
</br>

## 동기와 비동기 복제

- 복제 입장에서 동기와 비동기 방식은 다른 레플리카에 복제가 되는 타이밍을 기준으로 구분된다
- 동기 방식
    - 모든 레플리카 셋이 최신 데이터를 저장하는 것을 보장하므로, 리더 노드 장애 시 다른 노드로 전환하는 것이 비교적 간단하다
    - 하지만 동기 복제는 느리고, 특정 레플리카에 장애가 발생하면 쓰기가 중단되는 단점이 있다
    - 네트워크 장애가 발생하는 분산 시스템에서는 비현실적인 방법일 수 있음
- 비동기 복제
    - 가용성 측면에서 장점이 있다
    - 모든 레플리카에 최신 데이터가 있는지 보장할 수 없다
- 일반적으로는 동기와 비동기 방식을 적절히 혼합한 방법을 사용하여 복제를 수행한다

</br>

**새로운 팔로워 추가 시 필요한 과정**

1. 리더 노드의 스냅샷(Snapshot) 을 복사하여 새로운 팔로워 노드에 저장
1. 리더 노드에게 스냅샷 이후의 데이터 변경 내역(Backlog, 백로그)을 요청
1. 리더 노드의 백로그 처리 이후에 발생하는 데이터 변경을 새로운 팔로워 노드에 적용하여 동기화 완료

</br>
</br>

## 고가용성 유지 방식 - 자동 복구 흐름

1. 리더 상태 판단
    - Heartbeat 등을 사용하여 리더 노드의 상태를 판단
1. 새로운 리더 선출
    - 리더 노드가 장애로 판단되면, 새로운 리더 선출
    - 이 과정은 제어 노드(Control Node) 에 의해 리더를 지정하거나 참여 중인 노드 사이의 선거를 거치게 됨
    - 가장 최신 데이터를 가지고 있는 노드가 가장 적합한 리더로 선택
1. 시스템 재설정
    - 클라이언트가 새로운 리더 노드에 쓰기 요청을 보낼 수 있도록 Request Routing 처리
    - 이전 리더 노드가 시스템 변경을 인식하도록 처리

</br>

**자동 복구 처리의 모호함**

- 자연스러운 흐름이지만 모호한 부분이 존재한다
- 리더 노드 장애 여부와 네트워크 파티션 상태를 구분하기 어렵다
- 리더의 마지막 트랜잭션이 처리되지 않은 상태로 리더 노드 장애 발생 시 → 데이터 처리 방안 고려 필요
- 리더가 죽은 것에 대한 판단 기준
    - 하트비트에 대한 명확한 기준 필요
- 리더 복구 시 캐시와 데이터베이스의 부정합 문제 발생 가능성
- 스플릿 브레인 상황 예방 방안도 고려 필요
    - 분산 환경에서 각자 자신이 Leader 라고 착각하는 상태

</br>
</br>

## 다중 리더 복제

- 여러 노드가 동시에 쓰기 요청을 처리할 수 있도록 설계된 복제 방식
- 이때 각 노드는 쓰기를 처리하는 리더이면서 동시에 다른 리더에서 발생한 변경을 받아들이는 팔로워 역할을 함께 수행한다
- 아래 구조로 동작한다
    - 각 리더 노드는 자신이 받은 쓰기를 로컬 or 자신이 속한 데이터센터에 즉시 처리한다
    - 처리된 변경사항은 비동기적으로 다른 리더 노드들에게 전파
    - 결과적으로 모든 리더 노드가 서로의 변경 사항을 복제 받아 최종적으로 같은 데이터 상태에 수렴하는 것을 목표로 한다
- 이 구조는 마스터-마스터 복제, 액티브/액티브 복제라고도 불린다

</br>

**다중 리더 복제 - 배경**

- 단일 리더 복제의 경우 모든 쓰기 요청이 하나의 리더 노드로만 전달된다
- 리더와 물리적으로 먼 위치에서 쓰기 요청이 발생하면 네트워크 왕복 지연이 커진다
- 리더가 위치한 데이터센터에 장애가 발생하면 리더 승격(failover) 과정이 필요하고 그동안 쓰기가 중단될 수 있다
- 네트워크 분리 상황에서는 리더에 연결할 수 없는 클라이언트가 존재하며 이 경우 아예 쓰기작업이 불가능하다

**다중 리더 복제 - 유스케이스**

- 다중 데이터센터 운영
    - 각 데이터센터마다 자신만의 리더 노드를 둔다
    - 데이터센터 내부에서는 기존과 동일하게 리더-팔로워 복제를 수행
    - 데이터센터 간에는 각 리더가 다른 데이터센터의 리더에게 변경사항을 비동기적으로 복제
- 오프라인 작업과 협업 편집
    - 다중 리더 복제의 경우 항상 온라인 상태를 보장할 수 없는 환경에서도 쓰기 작업을 수행할 수 있는 구조이다
    - 인터넷 연결이 끊긴 상태에서도 동작해야하는 클라이언트 / 여러 사용자가 동시에 하나의 문서를 편집하는 협업 애플리케이션
    - 각 사용자가 자신의 로컬 환경에서 로컬 DB 를 통해 변경을 수행하고 해당 변경사항은 추후 온라인 상태가 되었을때 비동기로 변경사항을 병합한다

</br>
</br>

## 쓰기 충돌

- 다중 리더 복제에서 가장 큰 문제는 쓰기 충돌
- 서로 다른 두 리더에서 동일한 레코드가 동시에 수정되면 비동기 복제 과정에서 이 두 변경 사항이 만나 충돌한다
- 만약 해당 충돌을 동기적으로 감지하려고 한다면 다중 리더 복제의 장점이 사라진다
- 여러가지 충돌 해소방식을 고려해야한다

1. 충돌 회피
    - 충돌 자체를 피하는 방법
    - 특정 레코드(또는 사용자)의 모든 쓰기를 항상 동일한 리더로 강제 라우팅 → 특정 사용자의 요청을 항상 동일한 데이터센터로 보내고 그 데이터센터의 리더만 사용하도록 보장
    - 라우팅 규칙이 깨지거나 사용자가 이동하는 경우(알고리즘의 필요조건이 실패하는 경우 등)에는 충돌 회피가 실패할 수 있다

2. 일관된 상태 수렴
    - 충돌이 발생하더라도 시스템은 어떤 방식으로든 하나의 최종 상태로 결정되어야 함 → 수렴(convergence)
    - 최종 쓰기 승리(LWW, Last Write Wins) → 각 쓰기에 타임스탬프 or 증가하는 ID 를 부여하고 가장 큰 값을 선택하여 최종결과로 적용
        - 다른 쓰기의 내용이 완전히 사라질 수 있음, 데이터 유실의 위험
    - 리더 우선순위 기반 선택 → 각 복제 서버에 고유한 ID 를 부여하고 특정 서버에서 발생한 쓰기가 항상 우선하도록 규칙을 정함
        - 우선순가 낮은 서버의 쓰기가 무의미해짐
    - 값 병합 → 충돌한 값을 단순히 하나로 선택하지 않고 사전 순 정렬 후 연결 등의 병합 알고리즘 적용
        - 애플리케이션의 성격에 따라 다르다, 데이터 의미가 달라질 수 있다
    - 충돌을 명시적으로 기록 → 충돌 상태 자체를 저장하고 나중에 애플리케이션에서 사용자가 직접 충돌 해소

</br>
</br>

## 다중 리더 복제 토폴로지

- 토폴로지 : 데이터를 복제하는 경로를 의미
- 일반적인 분류
    - 원형
    - 별
    - 전체 연결 방식 등
- 무한 루프 방지를 위한 정보 전달
    - 특정 데이터를 처음 전달한 노드 식별 정보를 함께 전송
- 노드의 데이터 처리 방식
    - 자신이 전달한 데이터를 받으면 이미 처리한 것으로 간주하고 변경 사항을 무시

![토폴로지](./img/to.png)

- 원형 토폴로지 : 각 노드가 하나의 노드로부터만 쓰기를 받아 다음 노드로 전달, MySQL 에서 기본 제공
- 별 토폴로지 : 중앙 노드가 모든 쓰기를 받아 다른 노드로 전달, 구조가 단순
- 전체 연결 토폴로지 : 모든 리더가 다른 모든 리더에게 직접 쓰기를 전달, 내경함성이 높음

</br>

**단점**

- 원형, 별 토폴로지 단점
    - 하나의 노드 장애 시 다른 노드의 복제 메시지 흐름에 영향 → 노드 하나의 장애가 복제 흐름 전체에 영향을 주며 끊길 수 있음
    - 장애 노드 발생 시 경로 재설정은 수동 설정이 필요
    - 내결함성이 전체 연결 방식보다 낮음
- 전체 연결 토폴로지의 단점
    - 네트워크 지연의 차이로 복제 메시지의 순서가 어긋날 수 있음 → 버전 벡터(version vector) 같은 기법을 사용하여 해결

</br>

**전체 연결 토폴로지 - 복제 메시지의 순서가 어긋나는 문제 상황**

- `x=1` 이라는 연산을 `Leader1` 에서 수행 후 `Leader2`, `Leader3` 에 전파
- 전파 이후 `x = x + 1` 연산 수행
- 이때 문제는 전파 과정이 네트워크 지연으로 인해 `x = x + 1` 연산 이후 처리된다면 특정 `Leader` 는 데이터가 일치하지 않음
    - Leader 1 의 x : 2
    - Leader 2 의 x : 1
        - Leader 2 가 네트워크 지연이 발생한 상황
    - Leader 3 의 x : 2
- 해결책 → 버전 벡터 등 일관된 순서를 알 수 있는 기술을 사용해야함

</br>
</br>

## 리더 없는 복제

- 리더 없는 복제에서는 모든 복제 노드가 클라이언트의 쓰기 요청을 직접 받을 수 있도록 설계된 복제 구조형태
- 클라이언트가 하나의 노드만 바라보지 않고 같은 키의 복제본을 가진 여러 노드에게 동시에 쓰기 요청을 보낸다
- 이후 시스템이 코디네이터(coordinator) 노드를 두는 경우에는 코디네이터가 클라이언트를 대신해서 여러 복제 노드에 쓰기를 병려로 전달하고 결과를 취합한다
    - 예) AWS 의 Dynamo
    - 이 스타일은 아마존 Dynamo 계열에서 널리 사용하고 다이나모 스타일로 묶여 설명되곤 한다
- 코디네이터 노드
    - 제 3의 노드로 존재
    - 여러 노드에 값을 전달하거나 클라이언트가 직접 여러 노드로 요청 전달 후 응답을 기다려 성공 판단
- 모든 노드에 쓰기 가능으로 특정 노드 장애에 민감하지 않음
    - 어떤 노드든 쓰기를 받을 수 있기 때문에 특정 노드가 다운된 상태에서도 시스템은 다른 노드에 쓰기를 수행
    - 특정 노드는 해당 쓰기 내용을 반영하지 못한 채 오래된 값을 유지할 가능성이 있다 → 오래된 값을 읽을 가능성 존재
- 읽기와 쓰기는 일정 노드 이상에게 정상 응답 받아야 성공 요청 처리
- 애플리케이션 업데이터 처리
    - 응답 받은 여러 값을 분석하여 적절한 값을 선택해 오래된 데이터를 업데이트

</br>
</br>

## 읽기 복구

- 노드가 장애나도 쓰기, 복제, 읽기를 진행하므로 특정 노드가 오래된 값을 가질 가능성이 존재함 → 이를 해결하기 위해 읽기 복구를 수행
- 클라이언트는 읽기 요청을 한 노드에만 보내지 않고 여러 노드에 병렬로 읽기를 보냄 → 응답 중에는 최신값, 오래된 값들이 혼합되어 있음
- 이때 클라이언트(또는 코디네이터)는 각 응답에 포함된 버전 정보(버전 숫자, 타임스탬프, 벡터 등)를 비교해서 최신 값을 결정한다
- 그리고 시스템은 뒤처진 값을 반환한 노드에게 최신 값을 다시 써서 노드를 최신 상태로 변경한다
- 읽기가 자주 발생하는 상황에서 유용 → 읽기 트래픽이 충분히 자주 발생하면 읽기 자체가 복구 작업을 겸한다
- 읽기 빈도가 낮은 경우에는 단점
    - 오래된 데이터가 계속 남아있을 수 있고, 데이터 충돌 상황이 많이 발생할 수 있음

</br>
</br>

## 안티 엔트로피

- 읽기 복구는 조회한 값은 빠르게 복구하지만 조회되지 않는 키는 오랫동안 방치될 수 있다
- 안티 엔트로피는 시스템적으로 별도의 백그라운드 프로세스가 노드 간 데이터를 비교해서 누락된 데이터를 찾아 복사해준다
- 즉시성이 떨어질 수 있지만 결국 전체가 하나의 값으로 수렴하게 만드는 구조

</br>
</br>

## 정족수(Quorum)

- 리더 없는 복제 시스템에서 요청의 성공 여부를 결정하기 위해 필요한 특정 수 → 읽기, 쓰기
- 시스템의 일관성과 가용성에 따라 다르게 설정할 수 있다
- 쓰기 가용성 중요 시
    - 쓰기 쿼럼 수를 줄여서 사용
- 쓰기 일관성 중요 시
    - 쿼럼 수를 높이는 것으로 사용
- 흔히 복제본의 개수를 N, 쓰기 요청의 정족수를 W, 읽기 요청의 정족수를 R 로 가정한다면 W + R > N 이 되도록 설정한다
    - 읽기에서 R 개를 받았을 때 그 R 개 중 최소 하나는 가장 최근의 성공한 쓰기를 포함한 집계(W개) 와 반드시 겹친다는 개념
    - 겹치는 노드가 최신 값을 알고 있을 가능성이 높다

> 정족수 - 최신 값을 보장하기 위한 설정
>
> - 쓰기나 읽기 대상 노드 수를 읽기 정족수와 쓰기 정족수를 합한 것보다 적게 설정
> - 대상 노드 수 `N`
> - 쓰기 정족 수 `W`
> - 읽기 정족 수 `R`
> - `W + R > N` 설정으로 최소 하나의 노드는 최신값을 보장할 수 있다
>
> W + R > N 이라고해서 항상 최신 값을 읽는다는 것이 보장되진 않는다
>
> - 정족수 조건을 만족해도 시스템은 정상 동작 중에도 오래된 값을 반환할 수 있다
> - 예를 들어 쓰기 요청이 W 개의 노드에 기록되어 성공으로 판단되는 순간에도 나머지 노드에는 아직 쓰기가 전파되지 않았을 수 있다
> - 그리고 그 타이밍에 읽기 요청이 들어오면 읽기 요청이 응답을 빠르게 준 R개의 노드가 우연히 최신값을 반영하지 않은 노드들로 구성될 수 있다
> - 그래서 리더 없는 복제는 본질적으로 강한 일관성 보다는 최종적 일관성의 성격을 갖는 요구사항에 알맞는다

</br>

**느슨한 정족 수 (Sloppy Quorum), 암시된 핸드오프 (Hinted Handoff)**

- 정족수 모델에서는 특정 키는 홈 노드 라고 부르는 정해진 N 개의 노드에 저장된다
- 그런데 네트워크 분리나 장애로 인해 홈 노드들 중 일부에 접근할 수 없으면 W 나 R 을 만족시키지 못해 시스템이 오류를 반환할 수 있다
    - W: 쓰기에 대한 성공 정족수 개수
    - R: 읽기에 대한 성공 정족수 개수
- 이때 정족수가 만족되지 않아도 쓰기를 계속 진행하겠다 라는 방향을 선택한다는 것이 느슨한 정족수이다 → 내결함성 강화를 위해 사용되는 방법
- 느슨한 정족수에서 코디네이터는 홈 노드가 아니라도 현재 연결 가능한 다른 노드에 쓰기를 저장해서 일단 W 개의 성공을 수행 → 그러면 쓰기 요청은 실패하지 않고 계속 받아들여짐
- 하지만 이렇게 저장된 쓰기는 정상 위치(홈 노드)가 아니기 때문에 나중에 네트워크가 복구되면 시스템은 그 쓰기를 홈 노드로 옮겨야 한다
    - 이때 코디네이터(또는 임시 저장 노드)가 대신 받아둔 쓰기를 홈 노드로 전달하는 동작을 암시된 핸드오프라고 부른다
- 가용성을 얻는 대신에 더 많은 일관성 문제와 복구 복잡성을 감수하는 개념

</br>
</br>

## 동기 쓰기

- 리더 없는 복제 시스템은 동시 쓰기 상황이 발생함
- 동기 쓰기 감지 - 이전 발생(Causality)
    - 인과적인 순서를 의미하는 개념
        - 인과성 : 원인과 결과 사이에 순서를 부여한 것
        - 결과는 항상 원인 앞에 있어야 한다
    - 사건 이전 판단 : 발생한 이벤트가 무엇에 기반한 것인지 파악하여 판단
    - 클라이언트 요청시 이전 발생 정보를 전달
    - 이전 발생 카운터가 저장된 상태와 다른 경우 → 분기 판단
    - 나눠진 값들을 합친 후 다음 버전 생성

</br>

**램포트 타임스탬프(Lamport Timestamp)**

- 레슬리 램포터(Leslie Lamport) 가 제시한 방법
- 값이 여러 서버에 걸쳐 저장될 때, 특정 값이 이전에 저장된 것인지 알아야 할 때 사용하는 타임스탬프 → 즉 특정 데이터의 부분 순서, 인과관계를 순서화시키는 방법
- 일반적인 타임스탬프의 문제점
    - 일반적인 타임스탬프 사용시 여러 서버 사이에 비교하는 과정이 복잡하고 어렵다
    - 컴퓨터의 시계는 내부 진동자로 만들어지며, 진동자의 속도에 따라 실제 시각과 차이가 발생하게 된다
        - NTP (Network Time Protocol)를 사용하여 인터넷에서 시게를 주기적으로 맞추는 과정이 존재
    - 일반적인 시계는 불확실하다, 특정 시점에는 믿을 수 없을 수 있으며 여러 서버에 걸친 합의 가능한 값이 아니다
- 각 노드는 고유 식별자를 갖고 각 노드는 처리한 연산 개수를 카운터로 유지한다
- 즉 램포트 타임스탬프는 그냥 (카운터, 노드ID) 의 쌍이다
- 두 노드는 때때로 카운터 값이 같을 수 있다 이때 타임스탬프에 노드 ID 를 포함시켜서 각 타임스탬프는 유일해진다
    - 두 타임스탬프가 존재하면 카운터가 큰 것이 타임스탬프가 크다
    - 카운터 값이 같다면 노드 ID 가 큰 것이 타임스탬프가 크다
- 모든 노드와 모든 클라이언트가 지금까지 본 카운터 값 중 최댓값을 추적하고 모든 요청에 해당 최댓값을 포함시킨다는 목적
- 노드가 자신의 카운터 값보다 큰 최대 카운터를 가진 요청이나 응답을 받으면 바로 자신의 카운터를 그 최댓값으로 변경한다
- 이후 다음 연산에서 최댓값 + 1의 증가된 카운터 값을 가진다

> 예시
>
> - 노드 : 노드 1, 노드 2
> - 클라이언트 : 클라이언트 A, 클라이언트 B
> - 클라이언트 A 는 노드 2로부터 카운터 값 5를 받고 노드 1에게 최댓값 5를 보낸다
> - 그때 노드 1의 카운터는 1이라면 바로 5로 바뀌고 다음 연산은 증가된 카운터 값 6을 갖는다

> 버전 벡터와 다른점
>
> - 버전 벡터는 두 연산이 동시적인지 또는 어떤 연산이 다른 연산에 인과적으로 의존하는지를 구별하는 목적
> - 램포트 타임스탬프는 항상 전체 순서화를 강제한다. 램포트 타임스탬프의 전체 순서화로부터 두 연산이 동시적인지 또는 인과적으로 의존성이 있는지는 알 수 없다
> - 버전 벡터보다 크기가 더 작다

</br>

**버전 벡터**

- 클러스터의 노드별 카운터 집합

```json
{
    "A": 10,
    "B": 31,
    "C": 23
}
```

- 한 노드가 업데이트를 수행하면 그 노드에 대한 카운터 값을 증가시킴

```json
{
    "A": 10,
    "B": 32,
    "C": 23
}
```

- `B` 값이 31 → 32 로 증가 → B 노드에 대한 업데이트가 수행되었구나를 파악가능
- 이를 통해 동시 업데이트를 감지
- `{"A": 1, "B":1 }` 과 `{"A": 2, "B":1}` 을 보고 A 노드에 대한 업데이트 수행 파악 및 Base Version 확보
    - Base Version → `{"A": 1, "B":1 }`
- 이후 `{"A": 2, "B": 1}` 과 `{"A':1, "B": 2}` 두 값을 받음
- Base Version 과 비교할때 두 노드 모두 업데이트 된 값이므로 이때 "동시 업데이트 발생"을 파악할 수 있음
